{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:31:02.852781Z",
     "start_time": "2024-04-25T20:31:02.849955Z"
    }
   },
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import keras\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:30:12.541736Z",
     "start_time": "2024-04-25T20:30:12.451533Z"
    }
   },
   "source": [
    "(ds_train, ds_validation, ds_test), metadata  = tfds.load(\n",
    "    \"tf_flowers\", \n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'], \n",
    "    as_supervised=True, \n",
    "    with_info=True\n",
    ")"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:04:58.108622Z",
     "start_time": "2024-04-25T20:04:58.105313Z"
    }
   },
   "source": [
    "metadata"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:30:14.934976Z",
     "start_time": "2024-04-25T20:30:14.931439Z"
    }
   },
   "source": [
    "print(metadata.splits[\"train\"].num_examples)\n",
    "num_classes = metadata.features[\"label\"].num_classes\n",
    "labels = metadata.features[\"label\"].names\n",
    "print(num_classes)\n",
    "print(labels)"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a few images"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:30:16.727453Z",
     "start_time": "2024-04-25T20:30:16.517441Z"
    }
   },
   "source": [
    "\n",
    "samples = ds_train.take(4)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "for i,img in enumerate(tfds.as_numpy(samples)):\n",
    "    img_array, img_label_idx = img\n",
    "    ax = fig.add_subplot(2,2, i + 1)    \n",
    "    ax.imshow(img_array)    \n",
    "    ax.set_title(labels[img_label_idx])\n",
    "plt.show()"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:32:55.202193Z",
     "start_time": "2024-04-25T20:32:55.057716Z"
    }
   },
   "source": [
    "IMG_SIZE = 180\n",
    "\n",
    "resize_and_rescale = models.Sequential([\n",
    "    layers.Resizing(IMG_SIZE,IMG_SIZE),\n",
    "    layers.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "data_augmentation = models.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    keras.layers.RandomRotation(0.1),\n",
    "    keras.layers.RandomZoom(0.1)\n",
    "])\n",
    "\n",
    "def prepare_for_training(ds_subset, batch_size = 32, shuffle=False, augment=False):\n",
    "    ds_subset  =  ds_subset.map(lambda x, y: (resize_and_rescale(x), y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # shuffle the dataset if needed\n",
    "    if shuffle:\n",
    "        ds_subset = ds_subset.shuffle(1000)\n",
    "\n",
    "    # create data batches\n",
    "    ds_subset = ds_subset.batch(batch_size)\n",
    "\n",
    "    # apply data augmentation\n",
    "    if augment:        \n",
    "        ds_subset= ds_subset.map(lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    # Use buffered prefecting on all datasets\n",
    "    return ds_subset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "transformed_ds_train = prepare_for_training(ds_train, shuffle=True, augment=True)\n",
    "transformed_ds_val = prepare_for_training(ds_validation)\n",
    "transformed_ds_test = prepare_for_training(ds_test)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check how the images look like after processing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:33:35.885225Z",
     "start_time": "2024-04-25T20:33:35.058916Z"
    }
   },
   "source": [
    "samples = transformed_ds_train.take(4)\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "for i,img in enumerate(tfds.as_numpy(samples)):\n",
    "    batch_images, batch_labels = img\n",
    "    #print(np.min(img_array), np.max(img_array))\n",
    "    ax = fig.add_subplot(2,2, i + 1)    \n",
    "    ax.imshow(batch_images[0])    \n",
    "    ax.set_title(labels[batch_labels[0]])\n",
    "plt.show()"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:35:01.243135Z",
     "start_time": "2024-04-25T20:35:01.203456Z"
    }
   },
   "source": [
    "model = models.Sequential([    \n",
    "  layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name=\"input\"),  \n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:35:03.371595Z",
     "start_time": "2024-04-25T20:35:03.341816Z"
    }
   },
   "source": [
    "\n",
    "model.compile(optimizer='adam',\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model and visualize training history"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:35:56.911380Z",
     "start_time": "2024-04-25T20:35:07.605394Z"
    }
   },
   "source": [
    "epochs=20\n",
    "history = model.fit(transformed_ds_train,validation_data=transformed_ds_val, epochs=epochs)"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:02.850581Z",
     "start_time": "2024-04-25T20:36:02.847804Z"
    }
   },
   "source": [
    "history_dict = history.history\n",
    "val_acc_values = history_dict['val_accuracy']\n",
    "train_acc_values = history_dict['accuracy']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "train_loss_values = history_dict['loss']\n",
    "epochs_range = range(epochs)\n"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:04.430415Z",
     "start_time": "2024-04-25T20:36:04.268687Z"
    }
   },
   "source": [
    "## Plotting the training and validation loss\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_loss_values, 'r', label='Training loss')\n",
    "plt.plot(epochs_range, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "## Plotting the training and validation accuracy\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_acc_values, 'r', label='Training accuracy')\n",
    "plt.plot(epochs_range, val_acc_values, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Metrics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:08.952860Z",
     "start_time": "2024-04-25T20:36:08.035281Z"
    }
   },
   "source": [
    "## create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = [labels for imgs, labels in tfds.as_numpy(transformed_ds_test.unbatch())]\n",
    "y_pred_probs = model.predict(transformed_ds_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "\n",
    "fig, _ = plt.subplots(nrows=1, figsize=(10,10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(False)\n",
    "cf = confusion_matrix(y, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cf, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='d', ax=ax)\n",
    "plt.show()"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect model parameters\n",
    "\n",
    "Inspect the model parameters and see how many parameters are there in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:14.037024Z",
     "start_time": "2024-04-25T20:36:14.026087Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect learned features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:16.882825Z",
     "start_time": "2024-04-25T20:36:16.872006Z"
    }
   },
   "source": [
    "\n",
    "image_url = \"https://static.wixstatic.com/media/e6591e_3a5449fe774a4993a1166b1d33e233f7~mv2_d_1880_1253_s_2.jpg/v1/fill/w_1000,h_666,al_c,q_90,usm_0.66_1.00_0.01/e6591e_3a5449fe774a4993a1166b1d33e233f7~mv2_d_1880_1253_s_2.jpg\"\n",
    "image_path = tf.keras.utils.get_file(\"image_test\", image_url)\n",
    "img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:18.416302Z",
     "start_time": "2024-04-25T20:36:18.283557Z"
    }
   },
   "source": [
    "plt.imshow(img)"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:21.928781Z",
     "start_time": "2024-04-25T20:36:20.493012Z"
    }
   },
   "source": [
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_tensor = tf.convert_to_tensor(img_array)\n",
    "img_tensor = tf.expand_dims(img_tensor, 0) \n",
    "img_tensor = tf.divide(img_tensor, 255.0)\n",
    "scores = model(img_tensor)\n",
    "probs = tf.nn.softmax(scores).numpy().squeeze()\n",
    "class_idx = np.argmax(probs)\n",
    "print(f\"this image was classified as {labels[class_idx]} with a probability of {probs[class_idx]}\")"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:27.420596Z",
     "start_time": "2024-04-25T20:36:26.996338Z"
    }
   },
   "source": [
    "import math\n",
    "cnn_layers = [layer for layer in model.layers  if isinstance(layer, layers.Conv2D)] \n",
    "selected_layers = cnn_layers[:1]       \n",
    "features_extraction_model = models.Sequential(selected_layers)\n",
    "features_map = features_extraction_model(img_tensor).numpy().squeeze()\n",
    "num_fmaps = features_map.shape[-1]\n",
    "num_rows = math.ceil(num_fmaps / 6)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i, fmap in enumerate(np.rollaxis(features_map, axis=2)):\n",
    "    ax = fig.add_subplot(num_rows, 6, i + 1)\n",
    "    ax.grid(False)\n",
    "    ax.imshow(fmap, cmap='viridis')\n",
    "plt.show()"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:36:41.708285Z",
     "start_time": "2024-04-25T20:36:41.158107Z"
    }
   },
   "source": [
    "cnn_layer  = model.get_layer(\"conv2d_3\")\n",
    "features_map = cnn_layer(img_tensor)\n",
    "features_map = features_map.numpy().squeeze()\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i, fmap in enumerate(np.rollaxis(features_map, axis=2)):\n",
    "    ax = fig.add_subplot(4,4, i + 1)\n",
    "    ax.grid(False)\n",
    "    ax.imshow(fmap, cmap='viridis')\n",
    "plt.show()"
   ],
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:37:20.438763Z",
     "start_time": "2024-04-25T20:37:20.436283Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "MODELS_DIR = Path(\"models/flowers-model\")\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "TF_MODEL_PATH = MODELS_DIR.joinpath(\"model.keras\")"
   ],
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T20:37:25.433134Z",
     "start_time": "2024-04-25T20:37:25.370445Z"
    }
   },
   "source": [
    "model.save(TF_MODEL_PATH)"
   ],
   "execution_count": 45,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
